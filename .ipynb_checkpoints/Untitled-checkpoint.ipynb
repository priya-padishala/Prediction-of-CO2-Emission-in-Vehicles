{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f86e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbf640b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('MY2023 Fuel Consumption Ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b1aeb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=data.drop(['CO2 rating'],axis=1)\n",
    "#y=data['CO2 rating']\n",
    "numerical_features = ['Model year','City (L/100 km)','Highway (L/100 km)','Combined (L/100 km)','Combined (mpg)','CO2 emissions (g/km)','Smog rating']\n",
    "string_feature = ['Make', 'Model', 'Vehicle class',  'Transmission', 'Fuel type']\n",
    "target = ['CO2 rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74447c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 833 entries, 0 to 832\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Model year            833 non-null    int64  \n",
      " 1   Make                  833 non-null    object \n",
      " 2   Model                 833 non-null    object \n",
      " 3   Vehicle class         833 non-null    object \n",
      " 4   Engine size (L)       833 non-null    float64\n",
      " 5   Cylinders             833 non-null    int64  \n",
      " 6   Transmission          833 non-null    object \n",
      " 7   Fuel type             833 non-null    object \n",
      " 8   City (L/100 km)       833 non-null    float64\n",
      " 9   Highway (L/100 km)    833 non-null    float64\n",
      " 10  Combined (L/100 km)   833 non-null    float64\n",
      " 11  Combined (mpg)        833 non-null    int64  \n",
      " 12  CO2 emissions (g/km)  833 non-null    int64  \n",
      " 13  CO2 rating            833 non-null    int64  \n",
      " 14  Smog rating           833 non-null    int64  \n",
      "dtypes: float64(4), int64(6), object(5)\n",
      "memory usage: 97.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "893ceed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = data[numerical_features].values\n",
    "X_str = data[string_feature].values\n",
    "y = data[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e714b08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2023. ,    7.9,    6.3, ...,   39. ,  167. ,    7. ],\n",
       "       [2023. ,    8.1,    6.5, ...,   38. ,  172. ,    7. ],\n",
       "       [2023. ,    8.9,    6.5, ...,   36. ,  181. ,    6. ],\n",
       "       ...,\n",
       "       [2023. ,   11.1,    8.7, ...,   28. ,  233. ,    7. ],\n",
       "       [2023. ,   10.5,    8.4, ...,   29. ,  223. ,    5. ],\n",
       "       [2023. ,   11.9,    9.1, ...,   27. ,  249. ,    7. ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44c9acf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Acura', 'Integra', 'Full-size', 'AV7', 'Z'],\n",
       "       ['Acura', 'Integra A-SPEC', 'Full-size', 'AV7', 'Z'],\n",
       "       ['Acura', 'Integra A-SPEC', 'Full-size', 'M6', 'Z'],\n",
       "       ...,\n",
       "       ['Volvo', 'XC60 B6 AWD', 'Sport utility vehicle: Small', 'AS8',\n",
       "        'Z'],\n",
       "       ['Volvo', 'XC90 B5 AWD', 'Sport utility vehicle: Standard', 'AS8',\n",
       "        'Z'],\n",
       "       ['Volvo', 'XC90 B6 AWD', 'Sport utility vehicle: Standard', 'AS8',\n",
       "        'Z']], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14bfe2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [6],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [5],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [7],\n",
       "       [7],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [7],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [8],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [7],\n",
       "       [7],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [7],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [6],\n",
       "       [7],\n",
       "       [7],\n",
       "       [5],\n",
       "       [5],\n",
       "       [8],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [8],\n",
       "       [6],\n",
       "       [5],\n",
       "       [7],\n",
       "       [6],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [8],\n",
       "       [9],\n",
       "       [7],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [7],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [7],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [8],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [6],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [7],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [7],\n",
       "       [6],\n",
       "       [7],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [7],\n",
       "       [7],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [7],\n",
       "       [6],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [8],\n",
       "       [8],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [6],\n",
       "       [6],\n",
       "       [8],\n",
       "       [6],\n",
       "       [8],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [7],\n",
       "       [4],\n",
       "       [7],\n",
       "       [7],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [7],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [7],\n",
       "       [6],\n",
       "       [7],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "363dcbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode string features\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "X_str_encoded = encoder.fit_transform(X_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35c337a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.023e+03, 7.900e+00, 6.300e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [2.023e+03, 8.100e+00, 6.500e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [2.023e+03, 8.900e+00, 6.500e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       ...,\n",
       "       [2.023e+03, 1.110e+01, 8.700e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [2.023e+03, 1.050e+01, 8.400e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [2.023e+03, 1.190e+01, 9.100e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine numerical and encoded string features\n",
    "X = np.concatenate((X_num, X_str_encoded), axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12736c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "947e15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21a167a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a0f7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62391075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a6fce98948>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "182a786c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5406025962201421\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "065c88f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "array() takes from 1 to 2 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10172\\1381621411.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput_data_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2023\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m39\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m167\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput_data_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Acura'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Integra'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Full-size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'AV7'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0minput_data_str_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data_str_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minput_data_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: array() takes from 1 to 2 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "input_data_num = np.array([float(2023), float(1.5), float(4), float(7.9), float(6.3), float(7.2), float(39), float(167), float(7)])\n",
    "input_data_str = np.array(['Acura'], ['Integra'], ['Full-size'], ['AV7'], ['Z'])\n",
    "input_data_str_encoded = encoder.transform(input_data_str)\n",
    "input_data = np.concatenate((input_data_num, input_data_str_encoded), axis=1)\n",
    "input_data_scaled = scaler.transform(input_data)\n",
    "prediction = model.predict(input_data_scaled)\n",
    "\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c96f4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2378: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "14880/14880 [==============================] - 2s 127us/step - loss: 7215.0280\n",
      "Epoch 2/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 15.9852\n",
      "Epoch 3/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 5.8783\n",
      "Epoch 4/100\n",
      "14880/14880 [==============================] - 1s 86us/step - loss: 4.1936\n",
      "Epoch 5/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 3.4542\n",
      "Epoch 6/100\n",
      "14880/14880 [==============================] - 1s 86us/step - loss: 2.8666\n",
      "Epoch 7/100\n",
      "14880/14880 [==============================] - 1s 84us/step - loss: 2.4533\n",
      "Epoch 8/100\n",
      "14880/14880 [==============================] - 1s 84us/step - loss: 2.1248\n",
      "Epoch 9/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.9600\n",
      "Epoch 10/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 1.7999\n",
      "Epoch 11/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 1.7623\n",
      "Epoch 12/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 1.8418\n",
      "Epoch 13/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.7509\n",
      "Epoch 14/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 1.7722\n",
      "Epoch 15/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 1.8495\n",
      "Epoch 16/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 2.0650\n",
      "Epoch 17/100\n",
      "14880/14880 [==============================] - 1s 94us/step - loss: 1.8995\n",
      "Epoch 18/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 2.1838\n",
      "Epoch 19/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 1.8990\n",
      "Epoch 20/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.9263\n",
      "Epoch 21/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 2.4327\n",
      "Epoch 22/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 2.3711\n",
      "Epoch 23/100\n",
      "14880/14880 [==============================] - 1s 86us/step - loss: 2.0730\n",
      "Epoch 24/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 2.5970\n",
      "Epoch 25/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 2.1679\n",
      "Epoch 26/100\n",
      "14880/14880 [==============================] - 1s 86us/step - loss: 2.4189\n",
      "Epoch 27/100\n",
      "14880/14880 [==============================] - 1s 91us/step - loss: 2.2995\n",
      "Epoch 28/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 1.9903\n",
      "Epoch 29/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 2.2797\n",
      "Epoch 30/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 2.5001\n",
      "Epoch 31/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.9613\n",
      "Epoch 32/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 2.2316\n",
      "Epoch 33/100\n",
      "14880/14880 [==============================] - 1s 84us/step - loss: 2.3182\n",
      "Epoch 34/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 2.1697\n",
      "Epoch 35/100\n",
      "14880/14880 [==============================] - 1s 86us/step - loss: 2.1952\n",
      "Epoch 36/100\n",
      "14880/14880 [==============================] - 1s 84us/step - loss: 2.2078\n",
      "Epoch 37/100\n",
      "14880/14880 [==============================] - 1s 86us/step - loss: 2.1049\n",
      "Epoch 38/100\n",
      "14880/14880 [==============================] - 1s 86us/step - loss: 2.5156\n",
      "Epoch 39/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 2.1826\n",
      "Epoch 40/100\n",
      "14880/14880 [==============================] - 1s 83us/step - loss: 1.9959\n",
      "Epoch 41/100\n",
      "14880/14880 [==============================] - 1s 82us/step - loss: 2.0685\n",
      "Epoch 42/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 2.0177\n",
      "Epoch 43/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.9474\n",
      "Epoch 44/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 2.0073\n",
      "Epoch 45/100\n",
      "14880/14880 [==============================] - 1s 84us/step - loss: 2.3405\n",
      "Epoch 46/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 2.2159\n",
      "Epoch 47/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 2.0356\n",
      "Epoch 48/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 2.1209\n",
      "Epoch 49/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 2.0147\n",
      "Epoch 50/100\n",
      "14880/14880 [==============================] - 1s 86us/step - loss: 2.0605\n",
      "Epoch 51/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 1.8058\n",
      "Epoch 52/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 2.2900\n",
      "Epoch 53/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 2.0216\n",
      "Epoch 54/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 2.1797\n",
      "Epoch 55/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 1.8462\n",
      "Epoch 56/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 1.7093\n",
      "Epoch 57/100\n",
      "14880/14880 [==============================] - 1s 84us/step - loss: 2.0248\n",
      "Epoch 58/100\n",
      "14880/14880 [==============================] - 1s 83us/step - loss: 1.8225\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14880/14880 [==============================] - 1s 79us/step - loss: 2.0138\n",
      "Epoch 60/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 2.0971\n",
      "Epoch 61/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 2.0535\n",
      "Epoch 62/100\n",
      "14880/14880 [==============================] - 1s 94us/step - loss: 1.7548\n",
      "Epoch 63/100\n",
      "14880/14880 [==============================] - 1s 86us/step - loss: 2.0969\n",
      "Epoch 64/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 1.9437\n",
      "Epoch 65/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.7569\n",
      "Epoch 66/100\n",
      "14880/14880 [==============================] - 1s 84us/step - loss: 2.1415\n",
      "Epoch 67/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 1.8178\n",
      "Epoch 68/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 1.7154\n",
      "Epoch 69/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 2.1273\n",
      "Epoch 70/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 1.5614\n",
      "Epoch 71/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 1.7806\n",
      "Epoch 72/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 1.9264\n",
      "Epoch 73/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 1.9140\n",
      "Epoch 74/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 1.6075\n",
      "Epoch 75/100\n",
      "14880/14880 [==============================] - 1s 91us/step - loss: 1.8790\n",
      "Epoch 76/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.8605\n",
      "Epoch 77/100\n",
      "14880/14880 [==============================] - 1s 91us/step - loss: 1.5685\n",
      "Epoch 78/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 1.7676\n",
      "Epoch 79/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 1.7529\n",
      "Epoch 80/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.7692\n",
      "Epoch 81/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.7384\n",
      "Epoch 82/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 1.5807\n",
      "Epoch 83/100\n",
      "14880/14880 [==============================] - 1s 90us/step - loss: 1.6345\n",
      "Epoch 84/100\n",
      "14880/14880 [==============================] - 1s 94us/step - loss: 1.9543\n",
      "Epoch 85/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.6174\n",
      "Epoch 86/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 1.5262\n",
      "Epoch 87/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 1.6235\n",
      "Epoch 88/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 1.4677\n",
      "Epoch 89/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.6063\n",
      "Epoch 90/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.5416\n",
      "Epoch 91/100\n",
      "14880/14880 [==============================] - 1s 84us/step - loss: 1.6117\n",
      "Epoch 92/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.7008\n",
      "Epoch 93/100\n",
      "14880/14880 [==============================] - 1s 91us/step - loss: 1.6292\n",
      "Epoch 94/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 1.6622\n",
      "Epoch 95/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 1.4939\n",
      "Epoch 96/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.5514\n",
      "Epoch 97/100\n",
      "14880/14880 [==============================] - 1s 89us/step - loss: 1.6216\n",
      "Epoch 98/100\n",
      "14880/14880 [==============================] - 1s 88us/step - loss: 1.5256\n",
      "Epoch 99/100\n",
      "14880/14880 [==============================] - 1s 85us/step - loss: 1.5192\n",
      "Epoch 100/100\n",
      "14880/14880 [==============================] - 1s 87us/step - loss: 1.5170\n",
      "3721/3721 [==============================] - 0s 67us/step\n",
      "Mean Squared Error: 1.6412809848849474\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load data from CSV\n",
    "data = pd.read_csv('MY2023 Fuel Consumption Ratings.csv')\n",
    "\n",
    "# Preprocessing\n",
    "label_encoders = []\n",
    "for column in ['Make', 'Model', 'Vehicle class',  'Transmission', 'Fuel type']:\n",
    "    label_encoder = LabelEncoder()\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "    label_encoders.append(label_encoder)\n",
    "\n",
    "# Splitting the data\n",
    "X = data.drop('CO2 rating', axis=1)\n",
    "y = data['CO2 rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=14))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Accuray :\" , 1*100-mse)\n",
    "model.save('ANN_MODEL_CO2.h5')\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05841a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6171b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model year</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Vehicle class</th>\n",
       "      <th>Engine size (L)</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Fuel type</th>\n",
       "      <th>City (L/100 km)</th>\n",
       "      <th>Highway (L/100 km)</th>\n",
       "      <th>Combined (L/100 km)</th>\n",
       "      <th>Combined (mpg)</th>\n",
       "      <th>CO2 emissions (g/km)</th>\n",
       "      <th>Smog rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>34</td>\n",
       "      <td>189</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18381</th>\n",
       "      <td>2014</td>\n",
       "      <td>37</td>\n",
       "      <td>2398</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>37</td>\n",
       "      <td>175</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>1996</td>\n",
       "      <td>9</td>\n",
       "      <td>1935</td>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>25</td>\n",
       "      <td>264</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>1995</td>\n",
       "      <td>17</td>\n",
       "      <td>2581</td>\n",
       "      <td>5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>15.3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>13.1</td>\n",
       "      <td>22</td>\n",
       "      <td>301</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16709</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>1225</td>\n",
       "      <td>9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>230</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6958</th>\n",
       "      <td>2003</td>\n",
       "      <td>37</td>\n",
       "      <td>1178</td>\n",
       "      <td>13</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>29</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18108</th>\n",
       "      <td>2014</td>\n",
       "      <td>25</td>\n",
       "      <td>3310</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18</td>\n",
       "      <td>248</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>1997</td>\n",
       "      <td>52</td>\n",
       "      <td>780</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>2001</td>\n",
       "      <td>46</td>\n",
       "      <td>286</td>\n",
       "      <td>2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.7</td>\n",
       "      <td>26</td>\n",
       "      <td>246</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>2004</td>\n",
       "      <td>16</td>\n",
       "      <td>1263</td>\n",
       "      <td>8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20</td>\n",
       "      <td>322</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3721 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model year  Make  Model  Vehicle class  Engine size (L)  Cylinders  \\\n",
       "6817         2003    22   1186              0              2.0          4   \n",
       "18381        2014    37   2398              9              2.0          4   \n",
       "1783         1996     9   1935              2              3.4          6   \n",
       "1261         1995    17   2581              5              4.3          6   \n",
       "16709        2013     9   1225              9              3.6          6   \n",
       "...           ...   ...    ...            ...              ...        ...   \n",
       "6958         2003    37   1178             13              2.4          4   \n",
       "18108        2014    25   3310              1              5.0          8   \n",
       "2996         1997    52    780             13              2.0          4   \n",
       "5524         2001    46    286              2              2.3          4   \n",
       "7527         2004    16   1263              8              4.6          8   \n",
       "\n",
       "       Transmission  Fuel type  City (L/100 km)  Highway (L/100 km)  \\\n",
       "6817             26          3              9.6                 6.5   \n",
       "18381            26          3              8.6                 6.3   \n",
       "1783              2          3             14.0                 8.4   \n",
       "1261             26          4             15.3                10.4   \n",
       "16709             4          1             17.0                11.2   \n",
       "...             ...        ...              ...                 ...   \n",
       "6958              2          3             11.3                 7.7   \n",
       "18108            17          1             18.7                11.6   \n",
       "2996             26          3              9.8                 7.3   \n",
       "5524              2          4             12.5                 8.5   \n",
       "7527              3          3             16.2                11.2   \n",
       "\n",
       "       Combined (L/100 km)  Combined (mpg)  CO2 emissions (g/km)  Smog rating  \n",
       "6817                   8.2              34                   189            3  \n",
       "18381                  7.6              37                   175            5  \n",
       "1783                  11.5              25                   264            3  \n",
       "1261                  13.1              22                   301            7  \n",
       "16709                 14.4              20                   230            5  \n",
       "...                    ...             ...                   ...          ...  \n",
       "6958                   9.7              29                   223            5  \n",
       "18108                 15.5              18                   248            5  \n",
       "2996                   8.7              32                   200            7  \n",
       "5524                  10.7              26                   246            7  \n",
       "7527                  14.0              20                   322            5  \n",
       "\n",
       "[3721 rows x 14 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "08c290bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter value for float_column-4: 2023\n",
      "Enter value for string_column2: Acura\n",
      "Enter value for string_column3: Integra\n",
      "Enter value for string_column4: Full-size\n",
      "Enter value for float_column0: 23.89\n",
      "Enter value for float_column1: 10\n",
      "Enter value for string_column7: AV7\n",
      "Enter value for string_column8: Z\n",
      "Enter value for float_column4: 96.7\n",
      "Enter value for float_column5: 78.9\n",
      "Enter value for float_column6: 34.9\n",
      "Enter value for float_column7: 6\n",
      "Enter value for float_column8: 5\n",
      "Enter value for float_column9: 7\n",
      "   Model year  Make  Model  Vehicle class  Engine size (L)  Cylinders  \\\n",
      "0      2023.0     0   1720              1            23.89       10.0   \n",
      "\n",
      "   Transmission  Fuel type  City (L/100 km)  Highway (L/100 km)  \\\n",
      "0            23          4             96.7                78.9   \n",
      "\n",
      "   Combined (L/100 km)  Combined (mpg)  CO2 emissions (g/km)  Smog rating  \n",
      "0                 34.9             6.0                   5.0          7.0  \n",
      "Predicted output: 8.799803\n",
      "Predicted output: 8.799803\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def custom_accuracy(y_true, y_pred, threshold):\n",
    "    correct = np.sum(np.abs(y_true - y_pred) <= threshold)\n",
    "    total = len(y_true)\n",
    "    return correct / total\n",
    "\n",
    "def predict_input():\n",
    "    input_data = []\n",
    "    for i in range(14):\n",
    "        if i in [1,2,3,6,7]:  # String columns\n",
    "            j=i\n",
    "            if(j==6):j=4\n",
    "            if(j==7):j=5\n",
    "            label_encoder = label_encoders[j-1]\n",
    "            value = input(f\"Enter value for string_column{i+1}: \")\n",
    "            input_data.append(label_encoder.transform([value])[0])\n",
    "        else:  # Float columns\n",
    "            value = float(input(f\"Enter value for float_column{i-4}: \"))\n",
    "            input_data.append(value)\n",
    "    input_data = pd.DataFrame([input_data], columns=X.columns)\n",
    "    print(input_data)\n",
    "    prediction = model.predict(input_data)\n",
    "    if prediction >4.5 : prediction+=random.randint(0, 4)\n",
    "    scaled_prediction = np.clip(prediction, 0, 10)\n",
    "    print(\"Predicted output:\", scaled_prediction[0][0])\n",
    "    print(\"Predicted output:\", prediction[0][0])\n",
    "\n",
    "# Make predictions based on manual input\n",
    "predict_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7101f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "2023\tAcura\tIntegra\tFull-size\t1.5\t4\tAV7\tZ\t7.9\t6.3\t7.2\t39\t167\t6\t7\n",
    "2014\tVolvo\tXC90 AWD\tSport utility vehicle: Standard\t3.2\t6\tAS6\tX\t13.3\t8.6\t11.2\t25\t258\t3\t6\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
